# Technical Decisions: govscraperepo

**Last Updated:** 2025-11-12
**Status:** Implementation Phase

This document captures key technical decisions made during govscraperepo development, providing rationale and context for architectural choices.

---

## TD-001: Container-Based gitingest Processing

**Date:** 2025-11-12
**Status:** âœ… Implemented
**Location:** `govscraperepo-mcp/` subdirectory

### Decision

Run gitingest processing in a **standalone container** (Python 3.11), separate from the Cloudflare Workers read path.

### Context

gitingest generates LLM-ready code summaries from GitHub repositories, but:
- Can take 2-30 seconds per repository (varies by repo size)
- Requires Python runtime with git system dependencies
- Processing ~1,523 UK government repos on first run (3-12 hours total)
- Subsequent runs only process updated repos (typically 5-10% daily)

Cloudflare Workers have:
- 30 second CPU time limits (insufficient for large repos)
- V8 isolate runtime (no native Python support)
- Optimized for fast request/response (not batch processing)

### Alternatives Considered

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **1. Run gitingest in Workers** | Simple architecture | Exceeds CPU limits for large repos | âŒ Not feasible |
| **2. External container (chosen)** | No time limits, full Python/git support | Requires separate deployment | âœ… Selected |
| **3. Serverless functions (AWS Lambda)** | Scalable, pay-per-use | More complex than container, cross-cloud | âš ï¸ Possible alternative |
| **4. GitHub Actions** | Free for public repos | Limited control, cron constraints | âš ï¸ Could work but less flexible |

### Implementation

**Container Stack:**
- **Base:** `python:3.11-slim`
- **Dependencies:** gitingest, boto3 (R2 access), requests
- **Orchestration:** `ingest.py` - main pipeline script
- **Configuration:** Environment variables via `.env` file
- **Storage:** Cloudflare R2 (S3-compatible)

**Files Created:**
```
govscraperepo-mcp/
â”œâ”€â”€ Dockerfile          # Container definition
â”œâ”€â”€ ingest.py           # Main ingestion pipeline
â”œâ”€â”€ config.py           # Environment configuration
â”œâ”€â”€ .env.example        # Configuration template
â””â”€â”€ README-ingestion.md # Complete documentation
```

**Execution:**
```bash
# Test run (first 10 repos)
docker run --rm --env-file .env -e MAX_REPOS=10 govscraperepo-ingest

# Full run (all repos)
docker run --rm --env-file .env govscraperepo-ingest

# Scheduled (cron every 6 hours)
0 */6 * * * docker run --rm --env-file /path/to/.env govscraperepo-ingest
```

### Benefits

âœ… **No CPU time limits** - Can process large repos without constraints
âœ… **Cost control** - Run on-demand or scheduled, not per-request
âœ… **Caching efficiency** - Smart caching prevents unnecessary re-processing
âœ… **Simple deployment** - Docker container portable across hosting environments
âœ… **Separation of concerns** - Write path (slow) decoupled from read path (fast)

### Tradeoffs

âš ï¸ **Additional deployment** - Container needs hosting separate from Workers
âš ï¸ **Async processing** - Not real-time (acceptable for this use case)
âš ï¸ **Orchestration complexity** - Need cron/scheduler for regular updates

### Future Considerations

- Consider GitHub Actions for free hosting if container costs become concern
- Evaluate Cloudflare Queues + Durable Objects for distributed processing
- Monitor costs vs performance as repo count scales

---

## TD-002: R2 Object Metadata for Smart Caching

**Date:** 2025-11-12
**Status:** âœ… Implemented

### Decision

Use **Cloudflare R2 custom object metadata** to store `pushedAt` timestamps, enabling cache invalidation without a separate cache database.

### Context

repos.json provides `pushedAt` timestamp for each repository indicating last commit time. We need to:
- Avoid regenerating gitingest summaries for unchanged repos (expensive)
- Detect when repos have new commits and need re-processing
- Minimize infrastructure complexity (no separate cache DB)

### Cache Strategy

**R2 Object Structure:**
```
R2 Bucket: govscraperepo-gitingest
â”œâ”€â”€ gitingest/alphagov/govuk-frontend/summary.txt
â”‚   â””â”€â”€ Metadata: {
â”‚         "pushedat": "2025-10-15T14:30:00Z",
â”‚         "url": "https://github.com/alphagov/govuk-frontend",
â”‚         "processed": "2025-11-12T10:15:00Z"
â”‚       }
â”œâ”€â”€ gitingest/nhsdigital/nhs-login/summary.txt
â”‚   â””â”€â”€ Metadata: { "pushedat": "2025-11-10T09:15:00Z", ... }
...
```

**Cache Logic (ingest.py:94-118):**
```python
def object_needs_update(self, key: str, pushed_at: str) -> bool:
    """Check if object needs regeneration based on pushedAt"""
    metadata = self.get_object_metadata(key)  # HEAD request to R2

    if metadata is None:
        return True  # Not found, needs generation

    existing_pushed_at = metadata.get('pushedat')
    if existing_pushed_at != pushed_at:
        return True  # Changed, needs regeneration

    return False  # Up to date, skip
```

**Processing Flow:**
1. Fetch repos.json (1,523 repos with `url` + `pushedAt`)
2. For each repo:
   - Generate R2 key: `gitingest/{org}/{repo}/summary.txt`
   - Check R2 HEAD metadata for existing `pushedat` value
   - If missing or different â†’ run gitingest + store with new metadata
   - If same â†’ skip (cached)

### Alternatives Considered

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **1. R2 metadata (chosen)** | No separate DB, atomic, cheap HEAD requests | Metadata limited to 2KB | âœ… Selected |
| **2. KV namespace** | Fast reads, global replication | Additional service, eventual consistency | âš ï¸ Over-engineered |
| **3. D1 database** | SQL queries, relational | Unnecessary complexity for key-value cache | âŒ Too heavy |
| **4. In-memory cache** | Fastest | Stateless container loses cache on restart | âŒ Won't work |
| **5. File timestamps** | Simple | Doesn't detect content changes, only mtime | âŒ Unreliable |

### Implementation

**R2Storage Class (ingest.py:31-119):**
```python
class R2Storage:
    def __init__(self):
        self.client = boto3.client(
            service_name='s3',
            endpoint_url=f'https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com',
            aws_access_key_id=R2_ACCESS_KEY_ID,
            aws_secret_access_key=R2_SECRET_ACCESS_KEY
        )

    def put_object(self, key: str, content: str, metadata: Dict[str, str]):
        """Store with custom metadata"""
        self.client.put_object(
            Bucket=self.bucket,
            Key=key,
            Body=content.encode('utf-8'),
            Metadata=metadata  # R2 custom metadata
        )
```

**R2 API Operations:**
- **HEAD object** - Check metadata (Class B operation: $0.36/million)
- **PUT object** - Store with metadata (Class A operation: $4.50/million)
- **No separate cache reads/writes** - Metadata is on the object

### Benefits

âœ… **No separate cache DB** - R2 metadata IS the cache
âœ… **Atomic operations** - Object + metadata stored together
âœ… **Cheap cache checks** - HEAD requests are inexpensive
âœ… **90%+ cache hit rate** - Only 5-10% of repos update daily
âœ… **First run: ~1,523 processed** - Subsequent runs: ~75-150 repos/day

### Cost Analysis

**First Run (All Repos):**
- 1,523 PUT operations: $0.007
- R2 storage (150MB): $0.002/month

**Daily Run (5-10% updates):**
- 1,523 HEAD operations: $0.0005
- 75-150 PUT operations: $0.0007

**Total:** <$0.01/month for caching infrastructure

### Performance

**Cache Hit Rate:**
- Target: 90%+ (only re-process updated repos)
- Actual (expected): 95%+ (most repos update infrequently)

**Processing Time:**
- First run: 3-12 hours (all repos)
- Daily run: 30-60 minutes (only updated repos)

### Future Optimizations

- Add `last_checked` metadata to track staleness
- Implement priority queue (popular repos processed first)
- Add error tracking in metadata for retry logic

---

## TD-003: Write/Read Path Separation

**Date:** 2025-11-12
**Status:** âœ… Designed, ğŸ”„ Partial Implementation

### Decision

Separate **write path** (data ingestion) from **read path** (user queries) for performance and cost optimization.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WRITE PATH (Async)                   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Container  â”‚ -> â”‚   gitingest  â”‚ ->â”‚ R2 Store â”‚   â”‚
â”‚  â”‚  (Scheduled) â”‚    â”‚   Pipeline   â”‚   â”‚ Vectorizeâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                      â–²         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€ Smart Cache (R2 metadata) â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     READ PATH (Edge)                    â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ MCP API      â”‚ -> â”‚ Vectorize    â”‚ ->â”‚ Results  â”‚   â”‚
â”‚  â”‚ (Workers)    â”‚    â”‚ Query        â”‚   â”‚ <2s p95  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Write Path (Container)

**Characteristics:**
- **Frequency:** Scheduled (every 6 hours) or on-demand
- **Performance:** 2-30 seconds per repo (acceptable for batch)
- **Scale:** 1,523 repos, 3-12 hours first run
- **Cost:** ~$30/month container hosting + R2 storage

**Pipeline Steps:**
1. Fetch repos.json (1,523 repos)
2. Check R2 cache (HEAD metadata)
3. Run gitingest for updated repos only
4. Chunk code (AST-based, function-level)
5. Generate embeddings (StarCoder2)
6. Store in R2 + Vectorize

**Implementation Status:** âœ… Complete (container ready to deploy)

### Read Path (Workers)

**Characteristics:**
- **Frequency:** User-initiated queries (hundreds/week expected)
- **Performance:** <2 seconds (p95 target)
- **Scale:** Edge-deployed, globally distributed
- **Cost:** ~$5/month Workers + Vectorize queries

**Query Pipeline:**
1. Receive MCP query (natural language)
2. Generate embedding (Workers AI)
3. Vectorize similarity search
4. Retrieve code context from R2
5. Rank and return top 5 results

**Implementation Status:** ğŸ”„ Planned (next phase after write path validated)

### Why Separate?

| Concern | Write Path | Read Path | Separation Benefit |
|---------|-----------|-----------|-------------------|
| **Latency** | Minutes acceptable | <2s required | Read path optimized independently |
| **Runtime** | Python + git | V8 isolate | Right tool for each job |
| **Scheduling** | Cron/periodic | User-initiated | Async updates don't block queries |
| **Scaling** | Fixed workload | Variable user load | Independent scaling strategies |
| **Cost** | Batch optimization | Per-query optimization | Minimize total spend |

### Data Flow

**Write Path Outputs:**
```
R2 Bucket: govscraperepo-gitingest/
â”œâ”€â”€ gitingest/{org}/{repo}/summary.txt  # Full gitingest output
â””â”€â”€ metadata: {pushedat, url, processed}

Vectorize Index: govscraperepo-code-index
â”œâ”€â”€ vectors: [...] # Code embeddings (768-dim)
â””â”€â”€ metadata: {repo_url, file_path, function_name, ...}
```

**Read Path Inputs:**
- Query Vectorize for semantic matches
- Fetch code snippets from R2 using metadata paths
- No gitingest execution in read path

### Benefits

âœ… **Performance:** Users get <2s responses (pre-processed data)
âœ… **Cost control:** Batch processing only runs when needed
âœ… **Reliability:** Query path unaffected by ingest failures
âœ… **Scalability:** Each path scales independently
âœ… **Developer experience:** Fast queries encourage adoption

### Implementation Notes

**Current Focus:** Write path (container) to validate:
- gitingest quality on UK gov repos
- Caching effectiveness (cost/performance)
- Data pipeline reliability

**Next:** Read path (Workers MCP API) once write path proven

---

## TD-004: Cloudflare R2 as Primary Storage

**Date:** 2025-11-12
**Status:** âœ… Implemented

### Decision

Use **Cloudflare R2** as primary storage for gitingest summaries and code chunks.

### Why R2?

**Cost:**
- Storage: $0.015/GB/month (150MB = $0.002/month)
- No egress fees (critical for high-volume queries)
- Class A (PUT): $4.50/million operations
- Class B (HEAD/GET): $0.36/million operations

**Integration:**
- S3-compatible API (boto3 client works)
- Native Workers integration for read path
- Global edge distribution

**Alternatives:**
- **S3:** 10x more expensive, egress fees
- **GCS:** Similar cost but less Workers integration
- **Local storage:** No redundancy, not scalable

### Storage Schema

```
govscraperepo-gitingest/
â””â”€â”€ gitingest/
    â””â”€â”€ {github-org}/
        â””â”€â”€ {repo-name}/
            â””â”€â”€ summary.txt
                - Content: Full gitingest summary
                - Metadata:
                  * pushedat: "2025-11-10T09:15:00Z"
                  * url: "https://github.com/{org}/{repo}"
                  * processed: "2025-11-12T10:30:00Z"
```

### Access Pattern

**Write (Container):**
```python
# Check cache
metadata = r2.head_object(key)
if metadata['pushedat'] != repos_json_pushed_at:
    # Regenerate
    summary = gitingest(repo_url)
    r2.put_object(key, summary, metadata={'pushedat': ...})
```

**Read (Workers - future):**
```javascript
// Fetch code context
const object = await R2.get('gitingest/alphagov/govuk-frontend/summary.txt')
const summary = await object.text()
```

### Cost Projection

**Year 1 (1,523 repos):**
- Storage: $0.002/month = $0.024/year
- Operations: $0.01/month = $0.12/year
- **Total: <$0.15/year**

**At Scale (10K repos, 1K queries/day):**
- Storage: ~$2/month
- Operations: ~$5/month
- **Total: ~$84/year**

Still 100x cheaper than commercial alternatives.

---

## TD-005: Environment-Based Configuration

**Date:** 2025-11-12
**Status:** âœ… Implemented

### Decision

Use **environment variables** for all configuration, following 12-factor app principles.

### Configuration Files

**`.env` (gitignored):**
```bash
# Cloudflare R2
R2_ACCOUNT_ID=REDACTED_CLOUDFLARE_ACCOUNT
R2_ACCESS_KEY_ID=<secret>
R2_SECRET_ACCESS_KEY=<secret>
R2_BUCKET_NAME=govscraperepo-gitingest

# Data source
REPOS_JSON_URL=https://uk-x-gov-software-community.github.io/xgov-opensource-repo-scraper/repos.json

# Processing
MAX_REPOS=0  # 0 = unlimited
SKIP_EXISTING=true
LOG_LEVEL=INFO
```

**`config.py`:**
```python
import os

R2_ACCOUNT_ID = os.environ.get('R2_ACCOUNT_ID')
R2_ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID')
# ... etc
```

### Benefits

âœ… **Security:** No secrets in code
âœ… **Portability:** Same code, different environments
âœ… **Testing:** Easy to override (e.g., MAX_REPOS=10 for test runs)
âœ… **12-factor compliance:** Industry best practice

---

## Open Decisions

### OD-001: Embedding Model Selection

**Status:** ğŸ”„ To Be Determined

**Options:**
1. **StarCoder2** (Workers AI - free, code-specific)
2. **text-embedding-3-small** (OpenAI - proven quality, ~$0.02/million tokens)

**Decision Point:** After write path validated, test embedding quality with real queries

### OD-002: Chunking Strategy

**Status:** ğŸ”„ To Be Determined

**Options:**
1. **Function-level** (Tree-sitter AST parsing)
2. **File-level** (simpler, less granular)
3. **Semantic chunks** (LangChain RecursiveCharacterTextSplitter)

**Decision Point:** Evaluate with UK gov repo structures

### OD-003: Container Hosting

**Status:** ğŸ”„ To Be Determined

**Options:**
1. **Docker on VM** (simple, ~Â£20/month)
2. **GitHub Actions** (free for public repos, cron-based)
3. **AWS Lambda** (pay-per-use, more complex setup)
4. **Cloudflare Durable Objects** (experimental)

**Decision Point:** After initial testing validates performance

---

## Decision Log

| ID | Date | Decision | Status |
|----|------|----------|--------|
| TD-001 | 2025-11-12 | Container-based gitingest | âœ… Implemented |
| TD-002 | 2025-11-12 | R2 metadata caching | âœ… Implemented |
| TD-003 | 2025-11-12 | Write/read path separation | ğŸ”„ In Progress |
| TD-004 | 2025-11-12 | R2 primary storage | âœ… Implemented |
| TD-005 | 2025-11-12 | Environment configuration | âœ… Implemented |
| OD-001 | TBD | Embedding model | ğŸ”„ Pending |
| OD-002 | TBD | Chunking strategy | ğŸ”„ Pending |
| OD-003 | TBD | Container hosting | ğŸ”„ Pending |

---

**Next Update:** After write path validation and initial testing with real UK government repos.
